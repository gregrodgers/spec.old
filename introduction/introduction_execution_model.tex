% This is an included file. See the master file for more information.
%
% When editing this file:
%
%    1. To change formatting, appearance, or style, please edit openmp.sty.
%
%    2. Custom commands and macros are defined in openmp.sty.
%
%    3. Be kind to other editors -- keep a consistent style by copying-and-pasting to
%       create new content.
%
%    4. We use semantic markup, e.g. (see openmp.sty for a full list):
%         \code{}     % for bold monospace keywords, code, operators, etc.
%         \plc{}      % for italic placeholder names, grammar, etc.
%
%    5. There are environments that provide special formatting, e.g. language bars.
%       Please use them whereever appropriate.  Examples are:
%
%         \begin{fortranspecific}
%         This is text that appears enclosed in blue language bars for Fortran.
%         \end{fortranspecific}
%
%         \begin{note}
%         This is a note.  The "Note -- " header appears automatically.
%         \end{note}
%
%    6. Other recommendations:
%         Use the convenience macros defined in openmp.sty for the minor headers
%         such as Comments, Syntax, etc.
%
%         To keep items together on the same page, prefer the use of
%         \begin{samepage}.... Avoid \parbox for text blocks as it interrupts line numbering.
%         When possible, avoid \filbreak, \pagebreak, \newpage, \clearpage unless that's
%         what you mean. Use \needspace{} cautiously for troublesome paragraphs.
%
%         Avoid absolute lengths and measures in this file; use relative units when possible.
%         Vertical space can be relative to \baselineskip or ex units. Horizontal space
%         can be relative to \linewidth or em units.
%
%         Prefer \emph{} to italicize terminology, e.g.:
%             This is a \emph{definition}, not a placeholder.
%             This is a \plc{var-name}.
%

\section{Execution Model}
\label{sec:Execution Model}
\index{execution model}
The OpenMP API uses the fork-join model of parallel execution. Multiple threads of
execution perform tasks defined implicitly or explicitly by OpenMP directives. The
OpenMP API is intended to support programs that will execute correctly both as parallel
programs (multiple threads of execution and a full OpenMP support library) and as
sequential programs (directives ignored and a simple OpenMP stubs library). However,
it is possible and permitted to develop a program that executes correctly as a parallel
program but not as a sequential program, or that produces different results when
executed as a parallel program compared to when it is executed as a sequential program.
Furthermore, using different numbers of threads may result in different numeric results
because of changes in the association of numeric operations. For example, a serial
addition reduction may have a different pattern of addition associations than a parallel
reduction. These different associations may change the results of floating-point addition.

An OpenMP program begins as a single thread of execution, called an initial thread. An
initial thread executes sequentially, as if the code encountered is part of an implicit task region, called an
initial task region, that is generated by the implicit parallel region surrounding the whole
program.

The thread that executes the implicit parallel region that surrounds the whole program
executes on the \emph{host device}. An implementation may support
other \emph{target devices}. If
supported, one or more devices are available to the host device for offloading code and
data. Each device has its own threads that are distinct from threads that execute on
another device. Threads cannot migrate from one device to another device. The
execution model is host-centric such that the host device offloads \code{target} regions to
target devices.

When a \code{target} construct is encountered, a new \emph{target task} is generated.
The \emph{target task} region encloses the \code{target} region. The \emph{target task} is
complete after the execution of the \code{target} region is complete.

When a \emph{target task} executes, the enclosed \code{target} region is executed by an initial
thread.  The initial thread may execute on a \emph{target device}.  The initial thread executes
sequentially, as if the target region is part of an initial task region that is
generated by an implicit parallel region. If the target device does not exist or the implementation does not support the target
device, all \code{target} regions associated with that device execute on the host device.

The implementation must ensure that the \code{target} region executes as if it were executed in the data environment of the target device unless an \code{if} clause is present and the \code{if} clause expression evaluates to \plc{false}.

The \code{teams} construct creates a \emph{league of teams}, where each team
is an initial team that comprises an initial thread that executes the
\code{teams} region. Each initial thread executes sequentially, as if the
code encountered is part of an initial task region that is generated by an
implicit parallel region associated with each team.

If a construct creates a data environment, the data environment is created at the time the
construct is encountered. Whether a construct creates a data environment is defined in
the description of the construct.

When any thread encounters a \code{parallel} construct, the thread creates a team of itself
and zero or more additional threads and becomes the master of the new team. A set of
implicit tasks, one per thread, is generated. The code for each task is defined by the code
inside the \code{parallel} construct. Each task is assigned to a different thread in the team
and becomes tied; that is, it is always executed by the thread to which it is initially
assigned. The task region of the task being executed by the encountering thread is
suspended, and each member of the new team executes its implicit task. There is an
implicit barrier at the end of the \code{parallel} construct. Only the master thread resumes
execution beyond the end of the \code{parallel} construct, resuming the task region that
was suspended upon encountering the \code{parallel} construct. Any number of
\code{parallel} constructs can be specified in a single program.

\code{parallel} regions may be arbitrarily nested inside each other. If nested parallelism is
disabled, or is not supported by the OpenMP implementation, then the new team that is
created by a thread encountering a \code{parallel} construct inside a \code{parallel} region
will consist only of the encountering thread. However, if nested parallelism is supported
and enabled, then the new team can consist of more than one thread. A \code{parallel}
construct may include a \code{proc_bind} clause to specify the places to use for the threads
in the team within the \code{parallel} region.

When any team encounters a worksharing construct, the work inside the construct is
divided among the members of the team, and executed cooperatively instead of being
executed by every thread. There is a default barrier at the end of each worksharing
construct unless the \code{nowait} clause is present. Redundant execution of code by every
thread in the team resumes after the end of the worksharing construct.

When any thread encounters a \emph{task generating construct}, one or more explicit tasks are generated.
Execution of explicitly generated tasks is assigned to one of the threads in the current
team, subject to the thread's availability to execute work. Thus, execution of the new
task could be immediate, or deferred until later according to task scheduling constraints
and thread availability. Threads are allowed to suspend the current task region at a task
scheduling point in order to execute a different task. If the suspended task region is for
a tied task, the initially assigned thread later resumes execution of the suspended task
region. If the suspended task region is for an untied task, then any thread may resume its
execution. Completion of all explicit tasks bound to a given parallel region is guaranteed
before the master thread leaves the implicit barrier at the end of the region. Completion
of a subset of all explicit tasks bound to a given parallel region may be specified through
the use of task synchronization constructs. Completion of all explicit tasks bound to the
implicit parallel region is guaranteed by the time the program exits.

When any thread encounters a \code{simd} construct, the iterations of the loop associated with
the construct may be executed concurrently using the SIMD lanes that are available to
the thread.

When a \code{loop} construct is encountered, the iterations of the loop(s)
associated with the construct are executed in the context of its binding
region, if defined, and otherwise are executed once per thread that encounters
the construct. If the \code{loop} region binds to a \code{teams} region, the
encountering thread(s) may continue execution after the \code{loop} region
without waiting for all iterations to complete; the iterations are
guaranteed to complete before the end of \code{teams} region.  Otherwise, all
iterations must complete before the encountering thread(s) continue execution
after the \code{loop} region.

Any thread that encounters the \code{loop} construct may participate in the
execution of the iterations of its associated loop(s). If the \code{nodep}
clause is present on the construct, any participating thread may create a
team of threads, as if from a \code{parallel} construct, that may also
participate in the execution of the iterations.

%The set of iterations are partitioned into iteration subsets,
%where the iterations in each subset execute on the same thread or SIMD lane.
%Iterations in a given iteration subset execute as if enclosed by the same task.


%an implementation may
%choose to apply optimizations, parallelization, and/or vectorization, including
%scheduling loop iterations in ways that cannot be directly represented in
%OpenMP. When encountering a \code{concurrent} construct an implementation
%will not generate a new league of thread teams, but may use any thread teams
%currently available on which to execute.

The \code{cancel} construct can alter the previously described flow of execution in an
OpenMP region. The effect of the \code{cancel} construct depends on its
\plc{construct-type-clause}. If a task encounters a \code{cancel}
construct with a \code{taskgroup}
\plc{construct-type-clause}, then the task activates cancellation
and continues execution at the end of its
\code{task} region, which implies completion of that task.
Any other task in that \code{taskgroup}
that has begun executing completes execution unless it encounters a \code{cancellation}
\code{point} construct, in which case it continues execution at the end of its \code{task} region,
which implies its completion. Other tasks in that \code{taskgroup} region that have not
begun execution are aborted, which implies their completion.

For all other \plc{construct-type-clause} values, if a
thread encounters a \code{cancel} construct, it
activates cancellation of the innermost enclosing region of the type specified and the
thread continues execution at the end of that region. Threads check if cancellation has
been activated for their region at cancellation points and, if so, also resume execution at
the end of the canceled region.

If cancellation has been activated regardless of \plc{construct-type-clause},
threads that are
waiting inside a barrier other than an implicit barrier at the end of the canceled region
exit the barrier and resume execution at the end of the canceled region. This action can
occur before the other threads reach that barrier.

Synchronization constructs and library routines are available in the OpenMP API to
coordinate tasks and data access in \code{parallel} regions. In addition, library routines and
environment variables are available to control or to query the runtime environment of
OpenMP programs.

The OpenMP specification makes no guarantee that input or output to the same file is
synchronous when executed in parallel. In this case, the programmer is responsible for
synchronizing input and output statements (or routines) using the provided
synchronization constructs or library routines. For the case where each thread accesses a
different file, no synchronization by the programmer is necessary.
